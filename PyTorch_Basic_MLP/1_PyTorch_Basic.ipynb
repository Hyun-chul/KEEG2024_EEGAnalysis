{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_PyTorch_Basic.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNn8kAeBnnac5AntfI0Kpk7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["\n","참고문헌: 파이썬 딥러닝 파이토치 (이경택, 방성수, 안상준 지음), 정보문화사, 링크: https://gaussian37.github.io/dl-pytorch-snippets/"],"metadata":{"id":"JikuNre---P8"}},{"cell_type":"markdown","source":["# PyTorch 란?\n"],"metadata":{"id":"5DHCYh9A9ctd"}},{"cell_type":"markdown","source":["파이토치는 예전의 토치(Torch) 및 카페2(Caffe2) 프레임워크를 기반으로 한다. 이름에서 짐작하겠지만 파이토치는 파이썬을 스크립팅 언어로 사용하며, 진화된 토치 C/CUDA 백엔드를 사용한다. 카페2의 프로덕션 기능은 현재 파이토치 프로젝트로 편입되는 중이다.\n","\n","\b흔히 파토치를 \"강력한 GPU 가속이 적용되는 파이썬으로 된 텐서와 동적 신경망\"이라고 한다. "],"metadata":{"id":"CdZgmXd6mgGp"}},{"cell_type":"markdown","source":["# PyTorch 패키지의 구성 요소\n","\n","\n","* torch:  \n","    - main namespace로 tensor등의 다양한 수학 함수가 패키지에 포함되어 있습니다.\n","    - NumPy와 같은 구조를 가지고 있어서 numpy와 상당히 비슷한 문법 구조를 가지고 있습니다.\n","\n","\n","* torch.autograd\n","    - 자동 미분을 위한 함수가 포함되어 있습니다.\n","    - 자동 미분의 on, off를 제어하는 enable_grad 또는 no_grad나 자체 미분 가능 함수를 정의할 때 사용하는 기반 클래스인 Function등이 포함됩니다.\n","\n","\n","* torch.nn\n","    - 신경망을 구축하기 위한 다양한 데이터 구조나 레이어가 정의되어 있습니다.\n","    - CNN, LSTM, 활성화 함수(ReLu), loss 등이 정의되어 있습니다.\n","\n","* torch.optim\n","    - \bSGD 등의 파라미터 최적화 알고리즘 등이 구현되어 있습니다.\n","\n","* torch.utils.data\n","    - Gradient Descent 계열의 반복 연산을 할 때, 사용하는 미니 배치용 유틸리티 함수가 포함되어 있습니다.\n","\n","* torch.onnx\n","    - ONNX(Open Neural Network eXchange) 포맷으로 모델을 export 할 때 사용합니다.\n","    - ONNX는 서로 다른 딥러닝 프레임워크 간에 모델을 공유할 때 사용하는 새로운 포맷입니"],"metadata":{"id":"PVexlZvk9T8l"}},{"cell_type":"markdown","source":["# PyTorch 필요 스킬 소개\n","## 텐서의 생성과 변환"],"metadata":{"id":"vfvyRvYV-C4k"}},{"cell_type":"markdown","source":["- 텐서는 pytorch의 가장 기본이 되는 데이터 구조와 기능을 제공하는 다차원 배열을 처리하기 위한 데이터 구조입니다.\n","\n","- API 형태는 Numpy의 ndarray와 비슷하며 GPU를 사용하는 계산도 지원합니다.\n","텐서는 각 데이터 형태별로 정의되어 있습니다.\n","    torch.FloatTensor : 32bit float point\n","    torch.LongTensor : 64bit signed integer\n","\n","- GPU 상에서 계산할 때에는 torch.cuda.FloatTensor를 사용합니다. 일반적으로 Tensor는 FloatTensor라고 생각하면 됩니다.\n","\n","- 어떤 형태의 텐서이건 torch.tensor라는 함수로 작성할 수 있습니다.\n"],"metadata":{"id":"mlTTlPInCB1Z"}},{"cell_type":"code","source":["import torch\n","import numpy as np"],"metadata":{"id":"-RIDUokR-6qW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2차원 형태릐 list를 이용하여 텐서를 생성할 수 있습니다.\n","torch.tensor([[1,2],[3,4.]])\n","# : tensor([[1., 2.],\n","#         [3., 4.]])"],"metadata":{"id":"Bx7dpZHi_vYD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# device를 지정하면 GPU에 텐서를 만들 수 있습니다.\n","torch.tensor([[1,2],[3,4.]], device=\"cuda:0\")\n","# : tensor([[1., 2.],\n","#         [3., 4.]], device='cuda:0')"],"metadata":{"id":"4mzQIs0h_si1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dtype을 이용하여 텐서의 데이터 형태를 지정할 수도 있습니다.\n","torch.tensor([[1,2],[3,4.]], dtype=torch.float64)\n","# : tensor([[1., 2.],\n","#         [3., 4.]], dtype=torch.float64)"],"metadata":{"id":"rI-xL551_rtA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# arange를 이용한 1차원 텐서\n","torch.arange(0, 10)\n","# : tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"],"metadata":{"id":"iflBIb0-_obl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모든 값이 0인 3 x 5의 텐서를 작성하여 to 메소드로 GPU에 전송\n","torch.zeros(3, 5).to(\"cuda:0\")\n","# :tensor([[0., 0., 0., 0., 0.],\n","#         [0., 0., 0., 0., 0.],\n","#         [0., 0., 0., 0., 0.]], device='cuda:0')"],"metadata":{"id":"Y1zO5g3P_meA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# normal distribution으로 3 x 5 텐서를 작성\n","torch.randn(3, 5)\n","# : tensor([[-0.4615, -0.4247,  0.1998, -0.5937, -0.4767],\n","#         [ 0.7864,  0.3831, -0.7198, -0.0181, -1.1796],\n","#         [-0.4504, -1.3181,  0.2657,  0.6829, -1.1690]])"],"metadata":{"id":"JT25E2w5_kYJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 텐서의 shape은 size 메서드로 확인\n","t = torch.randn(3, 5)\n","t.size()\n","# : torch.Size([3, 5])"],"metadata":{"id":"MN3UDxnN_h_8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 텐서를 활용한 기본 연산"],"metadata":{"id":"hqhtRDoxBkfu"}},{"cell_type":"code","source":["tensor1 = torch.tensor([[[1., 2.], [3., 4.]], [[5., 6.], [7., 8.]]])\n","print(tensor1)"],"metadata":{"id":"8EcUgFlZCS0B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tensor2 = torch.tensor([[[9., 10.], [11., 12.]], [[13., 14.], [15., 16.]]])\n","print(tensor2)"],"metadata":{"id":"srCQuPnjCWmy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 덧셈\n","torch.add(tensor1, tensor2)"],"metadata":{"id":"Uv-9psgKCbVY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 뺄셈\n","torch.sub(tensor1, tensor2)"],"metadata":{"id":"Yfv0YJIFCbyW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 곱셈\n","torch.mul(tensor1, tensor2)"],"metadata":{"id":"oUbM0RW6CdfV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#나눗셈 \n","torch.div(tensor1, tensor2)"],"metadata":{"id":"ZL4nSq1RCfHm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# \b내적\n","torch.matmul(tensor1, tensor2)"],"metadata":{"id":"MpWJ0d-KCg8v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Numpy to Tensor 또는 Tensor to Numpy"],"metadata":{"id":"IW6eHv4gD5dF"}},{"cell_type":"markdown","source":["Numpy를 생성한 후 Tensor로 변환한 후 다시 Numpy로 변환해 보고 추가적으로 변환하는 방법도 알아보겠습니다."],"metadata":{"id":"nX_9FCiVEK6V"}},{"cell_type":"code","source":["import numpy as np\n","x1 = np.ndarray(shape=(2,3), dtype=int,buffer=np.array([1,2,3,4,5,6]))\n","# array([[1, 2, 3],\n","#        [4, 5, 6]])\n","\n","torch.from_numpy(x1)\n","# tensor([[1, 2, 3],\n","#         [4, 5, 6]], dtype=torch.int32)\n","        \n","x2 = torch.from_numpy(x1)\n","x2.numpy()\n","# array([[1, 2, 3],\n","#        [4, 5, 6]])\n","\n","x2.float()\n","# tensor([[1., 2., 3.],\n","#         [4., 5., 6.]])"],"metadata":{"id":"KZ611C9YDpYl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Autograd 사용법"],"metadata":{"id":"nEiFFuIEEk8-"}},{"cell_type":"code","source":["import torch\n","\n","w = torch.tensor(2.0, requires_grad = True)"],"metadata":{"id":"beBXsDOMEuPg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = w**2"],"metadata":{"id":"0Kd931q7E88f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["z = 2*y+5"],"metadata":{"id":"7472WLTUE9HL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["z.backward()"],"metadata":{"id":"6sZ9ZzMqE7fW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('수식 w로 미분한 값 : {}'.format(w.grad()))"],"metadata":{"id":"rZJ8CNigE-uL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## PyTorch Import 모음"],"metadata":{"id":"gHX9jNeQCaQ3"}},{"cell_type":"code","source":["import torch\n","import torchvision\n","\n","# neural network 모음. (e.g. nn.Linear, nn.Conv2d, BatchNorm, Loss functions 등등)\n","import torch.nn as nn \n","\n","# Optimization algorithm 모음, (e.g. SGD, Adam, 등등)\n","import torch.optim as optim \n","\n","# 파라미터가 필요없는 Function 모음\n","import torch.nn.functional as F \n","\n"," # 데이터 세트 관리 및 미니 배치 생성을 위한 함수 모음\n","from torch.utils.data import DataLoader\n","\n","# 표준 데이터 세트 모음\n","import torchvision.datasets as datasets \n","\n","# 데이터 세트에 적용 할 수있는 변환 관련 함수 모음\n","import torchvision.transforms as transforms \n","\n","# cudnn을 다루기 위한 값 모음\n","import torch.backends.cudnn as cudnn \n","\n","# summary를 통한 model의 현황을 확인 하기 위함\n","from torchsummary import summary \n","\n","# model을 onnx 로 변환하기 위함\n","import torch.onnx \n"],"metadata":{"id":"lYybvCWDF28g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## GPU 셋팅 관련 코드"],"metadata":{"id":"cXhykPjYGJxj"}},{"cell_type":"code","source":["# cuda가 사용 가능한 지 확인\n","torch.cuda.is_available()\n","\n","# cuda가 사용 가능하면 device에 \"cuda\"를 저장하고 사용 가능하지 않으면 \"cpu\"를 저장한다.\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 멀티 GPU 사용 시 사용 가능한 GPU 셋팅 관련\n","# 아래 코드의 \"0,1,2\"는 GPU가 3개 있고 그 번호가 0, 1, 2 인 상황의 예제입니다.\n","# 만약 GPU가 5개이고 사용 가능한 것이 0, 3, 4 라면 \"0,3,4\" 라고 적으면 됩니다.\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"\n","\n","# 현재 PC의 사용가능한 GPU 사용 갯수 확인\n","torch.cuda.device_count()\n","\n","# 사용 가능한 device 갯수에 맞춰서 0번 부터 GPU 할당\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(list(map(str, list(range(torch.cuda.device_count())))))\n","\n","# cudnn을 사용하도록 설정. GPU를 사용하고 있으면 기본값은 True 입니다.\n","import torch.backends.cudnn as cudnn\n","cudnn.enabled = True\n","\n","# inbuilt cudnn auto-tuner가 사용 중인 hardware에 가장 적합한 알고리즘을 선택하도록 허용합니다.\n","cudnn.benchmark = True"],"metadata":{"id":"QtuTPxQoGK3H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["위 코드와 같이 device의 유형을 선택하면 GPU가 존재하면 cuda:0에 할당되고 GPU가 없으면 cpu에 할당 되도록 할 수 있습니다."],"metadata":{"id":"cgvVobrbGQ0e"}}]}